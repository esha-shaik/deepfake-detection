{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess, json, tqdm, os\n",
    "import torch, torchaudio, torchvision.transforms as T\n",
    "import torchaudio, transformers, torch\n",
    "import random\n",
    "from typing   import List, Tuple\n",
    "# import cv2\n",
    "\n",
    "from torchcodec.decoders import VideoDecoder              # torchcodec 0.3.0\n",
    "from transformers        import AutoModel, AutoProcessor   # transformers 4.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f119fcb",
   "metadata": {},
   "source": [
    "If you have access to the cloned github/video data. Run this as a sanity check that you have access to the vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a3441e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"image-data/9s4baJE29mP6-0Nk-KJRoS7TV34.jpg\"\n",
    "def read_csv(path):\n",
    "    with open (path) as rf:\n",
    "        reader = csv.DictReader(rf)\n",
    "        rows = []\n",
    "        # print(reader)\n",
    "        row_lens = dict()\n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "            # print(row)\n",
    "            if not ((len(row)) in row_lens.keys()):\n",
    "                row_lens[len(row)] = 1\n",
    "            else:\n",
    "                row_lens[len(row)] += 1\n",
    "        return rows\n",
    "    csv.DictReader() \n",
    "    \n",
    "def check_all_names_found (media_file, metadata_file):\n",
    "    imgFileList = os.listdir(media_file)\n",
    "    csv_rows = read_csv(metadata_file)[1::]\n",
    "    found_count = 0\n",
    "    not_found_count = 0\n",
    "    found_files = []\n",
    "    not_found = []\n",
    "    for r in csv_rows:\n",
    "        # print(r)\n",
    "        name = r[\"Filename\"]\n",
    "        if (name in imgFileList):\n",
    "            found_count += 1\n",
    "            found_files.append(name)\n",
    "            # if ()\n",
    "        else:\n",
    "            not_found_count += 1\n",
    "            not_found.append(name)\n",
    "        # print(r[\"Filename\"])\n",
    "    # print(csv_rows)\n",
    "    print(f\"FOUND: {found_count}\")\n",
    "    print(f\"NOT FOUND #: {not_found_count}\")\n",
    "    print(f\"NOT FOUND #: {not_found}\")\n",
    "    return np.array(found_files)\n",
    "\n",
    "def load_vid(file):\n",
    "    file = \"video-data/\" + file\n",
    "    cap = cv2.VideoCapture(file)\n",
    "    #get all of the dimensions of the video for the numpy array\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    \n",
    "    rgb_count = np.zeros((frame_count, height, width, 3), dtype = np.uint8)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open vid\")\n",
    "    for i in tqdm(range(frame_count)):\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        # print(f\"Frame length of vid: {frame_count}\")\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            return\n",
    "        \n",
    "        rgb_count[i] = frame[..., ::-1] ## cv2 tyrants used bgr instead of rgb, need to invert it \n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    print(f\"height: {height}\")\n",
    "    print(f\"width: {width}\")\n",
    "    return rgb_count\n",
    "\n",
    "\n",
    "def load_vid_list(files, label):\n",
    "    num = len(files)\n",
    "    label_col = np.full(num, label)\n",
    "    \n",
    "    for i in tqdm(range(num)):\n",
    "        cap = cv2.VideoCapture(\"video-data/\" + files[i])\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(\"Cannot open vid\")\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        \n",
    "        rgb_count = np.zeros((frame_count, height, width, 3), dtype = np.uint8)\n",
    "        \n",
    "        for j in range(frame_count):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"video that failed: video-data/{files[i]}, skipping now\")\n",
    "                i += 1\n",
    "                break\n",
    "            rgb_count[j] = frame[..., ::-1]\n",
    "        \n",
    "    \n",
    "    return rgb_count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37727b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND: 2035\n",
      "NOT FOUND #: 0\n",
      "NOT FOUND #: []\n"
     ]
    }
   ],
   "source": [
    "clean_vids = check_all_names_found(\"video-data/\", \"video-metadata-publish.csv\")\n",
    "\n",
    "def clear_unknowns(clean_vids, metadata_file):\n",
    "    csv_rows = read_csv(metadata_file)\n",
    "    bof = {\"Real\": [], \"Fake\": []}\n",
    "    for row in csv_rows:\n",
    "        vL = row[\"Video Ground Truth\"]\n",
    "        aL = row[\"Audio Ground Truth\"]\n",
    "        if vL == \"Real\" and aL == \"Real\":\n",
    "            bof[\"Real\"].append(row[\"Filename\"])\n",
    "        elif vL == \"Fake\" and aL == \"Fake\":\n",
    "            bof[\"Fake\"].append(row[\"Filename\"])\n",
    "    return bof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eced3a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND: 2035\n",
      "NOT FOUND #: 0\n",
      "NOT FOUND #: []\n",
      "{'Real': ['HICemuEclIn-ZDbqZVUULNCfNMI.mp4', 'kAaNHcuBnFPnxe4tspbxc_muFTw.mp4', '7QkcRIbGeqPx-3lRLNVEoF3Z9MM.mp4', 'rN7AySTzGxCHYrDYJcrqqN9ybNc.mp4', 'YBy7OnWBQ3GOQzm53dEEQv3_YBk.mp4', 'nefJI_4TbHarNctRfXP_pXxf4fg.mp4', '5lFghVsgAMh2mS_6lW4dNxa3Ma0.mp4', '_jB8v1mKu-G-YtCcsbCDz-Xqy7I.mp4', 'ZhGDGjAEcmCeKMaL7n2EHc4QtO8.mp4', 'C2itTABNRmzZt3NMWX5xtgV2E-g.mp4', 'JcazzdNzkDMktnDR6iORAoJzRNs.mp4', 'KNRJMAZi9TCdajnupiEMw4vDyl0.mp4', 'tMZRLQlh4tgT49AIODi_H44tHTA.mp4', 'S-M6eZeqaT8FOPEgHpUeboW4DIc.mp4', 'DtE_ZtU_z3fU4DSIvU4h9COtvno.mp4', 'lwf0nbH97hWa6zRYnkyRtIvynzQ.mp4', '5_sVFeQ4JyHtu2bIysyApXAtDyI.mp4', 'qtusd7VLnWcHTJtQjmVjTednP3c.mp4', '_-v4jJibKTSv-slQIrt8DfnwrRU.mp4', 'ylUxctRpgu_Aqya7Mg268MLaf5M.mp4', 'CV8UPfKVejNrpp5mgEcJQibabCw.mp4', '-wHhS6r-xuXnfOId95KMz5YTuJ4.mp4', 'fnGAuF4EzmmT1UhGMMHv2MwrOW8.mp4', 'hGah7PGiNDWpPJFWDGizAas1hzU.mp4', 'jBj3uM9aJU_N2Q6Lafb3BJS_S6g.mp4', 'TVPSrhfYU9_VIS47bAehJggz83c.mp4', 'kiuaxEn9qpF8h4WbN064opCsPN4.mp4', '1f7c9HfZIVvmEpmJABVOojiO4vM.mp4', 'swocXDcOodUt1MJmPPX4enby2T0.mp4', '4XzHAfqrKw_m6OJWt_Bnp0kjYto.mp4', 'YJGNsnHTU4rfvf44EbJ6emEEZY8.mp4', 'P8ogCNM0G6ewg9FTiufhus5ycy4.mp4', 'qBdQVfKR2itXJtQHKg1EMbKTJP0.mp4', '3mRAH7wzQuK3-mHj3C-tUnLPncA.mp4', 'vq9orS7NHhqBGmUnFI1Jn9myRLs.mp4', 'iKexCezSLgzrxT7K4eld2ia3pS0.mp4', 'cVP9TRgZifY966_tjAZRAqdSDgs.mp4'], 'Fake': ['xuvcrU3PUW7SKnY-mf516bpFF4Y.mp4', 'voJkcXmcmjx6DxdogcYOC-BWra4.mp4', 'etd8OpE2gGAoFf0og8xRAoQAdSc.mp4', 'H462GW5eoTsmQB2rf2za7C_lXOM.mp4', 'nPvrD_PysEWpwXJRqNoec2YJk18.mp4', 'ypzOowTOrcZJBGWHzb3H4RKwkMs.mp4', 'BWiqL1I_SDwf9bmkmjvuI4nXwHg.mp4', 'cVLZx0A7HvfYG7HawBahHTkOE1A.mp4', 'mifUHHyIwdGdjm7AY2nkAVBrtJc.mp4', '_3WXFdNlJ_FNF_IkvCNC6RKXrrk.mp4', 'lDG0RZKRDJMBe3XOBAelN4G2vD4.mp4', 'nSrfcDk1iGUR4nyPN9KC_hm1D_U.mp4', 'SAL7Z4DFF9I9rhYAQoni3UoE0i8.mp4', '1-q90cwQEaQm-SPVjyYjLMvP13k.mp4', '8MQB8CC0fquHh6bzP5U4-WtlPG0.mp4', '2nyd7vAmeMmenQ1zJ-vLPeLgSLg.mp4', 'm3T-96PUsV3OSu9jX59bHti2hDk.mp4', 'fi6nAIdTwcJspdUEqQophmV8ubc.mp4', '6jVS13Ieb843X_52YUih9tSOf44.mp4', 'Mt7htiUkk4ZPIA4J9W_5fPfxfBU.mp4', '5_TtMRz_wcsItV1-4qQIgzfUpRQ.mp4', 'pMZ4SvFs8V7-fwpDQEHBypeIz9E.mp4', 'qMXaWWhbj8DYoBUP0gn6EelWpGE.mp4', '9iQfk7jb-degP7HZbZa_GBxywes.mp4', 'MweDYEH5Rijp1Gi1P-gf2bkMSwk.mp4', 'NMjaTaw8h4_McbEE6RavftFbhhs.mp4', 'PCFrjETFR3x4DFBbKxglrhJbr1Q.mp4', 'kugkpfPmho0M6Ytpb0lXR1KXqpw.mp4', 'jGYnSuXUjdStf_-VywHAOSn0hHg.mp4', 'Epg8YZquEf2aECOLjWcNILIu23M.mp4', '1c4D1NkzDZGJl4di5JxndBOnZjo.mp4', 'RjY6yg9VJsrAphVBvy9gGwH6rUA.mp4', 'ZxN7pptM2MCugdN6Aao7WSnWlXM.mp4', 'kjiisZC7tQGOuvIWYYSlhKxMC-E.mp4', 'v0tftQceFM-D16S7qpPm5e9xlFA.mp4', '0XNGODO3HoA-NWPOgiK85Zx22vY.mp4', '2u-UPRafrMGF1WDVsYDKP7YV7bc.mp4', 'fkuL4dWYKGmWF6lkaKsU4NiJtOA.mp4', 'UKv3Xh5IeKXuzYdgNoTiNIGBPqQ.mp4', 'NX6uCDY2zlZxwvYH3xQTel5Bvow.mp4', '4kbkJ7a5xmdAeGY73ZvtwEP_IA0.mp4', 'HJrnYG-XfXZI1PbDe2btuJvGF-s.mp4', 'RVjcvziLOMuDnfi5b3EZoNa9Svw.mp4', 'F108gfBs5RxBWqWxWtwxhL97GyU.mp4', 'Fb51vXamylhatmpWLRQPTdTs35I.mp4', 'cMgkllZc82W-cJ0NMR34F52Z-uI.mp4', '5hjKKRlptrV0PPcCGNeGduwjbPQ.mp4', 'eWtpNvG8bfcHGsYyHEf9WoMOUuc.mp4', '-VOMj_bejYFl2P7LMn87HY112R8.mp4', 'YQGQPuZfNANrj3yoBbGtP-mu9BE.mp4', 'EKUkdWZLt7q1jdIOjWE5bEHeQZo.mp4', '01W7xPE98uDILZgJxW2v_b0gWi8.mp4', 'zpVZG1fcNOM3K1f7uqNPaW8JwQA.mp4', '-zUphNuZtLCxi1ciFDRjQmyhRJ8.mp4', 'nVkgsUrr0_6UwWLaaJBdBHSKIkk.mp4', 'kQSrJWfpKDnA6Ibzcqsm9GadWOA.mp4', 'NLYgdLzbhccPscY8qLogGlz2WEg.mp4', 'G1cUW7ro2be0NUkGmsBQtfOgSts.mp4', 'MpcNhvCpG-eGvvDFsBi6AOZrGlw.mp4', 'SUvTHGc_GTnMLFqJNl5bFkeWv3A.mp4', '-UOS1SnHSN4RZ-n49BM7RR5Nv10.mp4', '4ZMBOJKFbZFJKLgrvgq0AC8CJOY.mp4', 'ocWsr4tf8_duIcr0793K73nrNZ4.mp4', 'FJlbOUCoJOIaeKUIqNxPa_EHsQk.mp4', 'Xe9i82hZecPA4bWe2WAJrDW9t9Y.mp4', 'HnnxgCst4tkDO18QXcYGuA72Puo.mp4', 'Z9rBREBwJ17CZ2DHTjqBnC_BHAs.mp4', 'cyVb-gioAWqdE3eUHfzxGrNhu9E.mp4', '-MhXUcte6wYK67zEP2YFkRPe6UM.mp4', 'QAgWiw9Xu8sKtb469Oy4wfG80Z4.mp4', 'DqGycGE3uN9NdgvpjQC_Z0WP2ao.mp4', '40Lgj5yXiuUnOziqeV0UAMAK3u0.mp4', 'HBF50BQ4glgJI5pTehUipuIqxys.mp4', 'r-H04gOwE5rja6Yrpw0ZsLrY1U0.mp4', 'WngkBTNn7RwhbpCd93nud7PAQ70.mp4', 'EZoFMgB5AblUQ8iKUlg_kWDe1D8.mp4', 'lIQxBcZMpoElxqHpinQSMyZ-7e0.mp4', 'qQ8q_n99mnVYXB8kMwJDsWDPayc.mp4', 'keRJ9BKvux2TxtTmVPxKjzUppVQ.mp4', 'vaXwKr7DeIamzGy3xccB3-2P6es.mp4', 'ae4D5OdsMa6df6IgSMOlhFawkJc.webm', '1wvkPd4APw1957-tPIa2z2E1HG4.mp4', '_hZBvDuxnZinge1_tXyvdOTwAuA.mp4', 'KZK_BSDGTiFgWhLm3VUIk6OL_S4.mp4', 'cDNqcLkxB0vz_7VT6hiJGrvpMxU.mp4', '7Fk5fTPep_wwpXLkhzMTx7jBCvE.mp4', 'V192QWlYK1kQKJPUolMXSs7X0nU.mp4', 'z8Qc36hHmPahq_7WgtrKT4_wSSQ.mp4', 'SitoCzWaph6iho0TDbA2QhbtyBs.mp4', '0QvtWN3nPkNtkZ37yIWu0Yx2GnA.mp4', 'opS7zk21aZa6ZrCvrVU892qDaow.mp4', '8bKggxfKYXyz7uCqgdQG4FkRf90.mp4', 'Z8lqHjPcZN35JShonrM88vbqwB4.mp4', 'lOEAEzZkJExduj6J0vsWOv1-E4E.mp4', '_SF2jjyQEZ2CZ6GADk7YegU9IYQ.mp4', '4RjIUTIZ_db7ZL30PlVRho-0FnM.mp4', '5Q4NGDLktIcSi7mzb4uOGFogKLg.mp4', 'nWybYWtUiXWpSlzO07SW0sU2tKE.mp4', 'TjgIhTHO1DuwjWnixtdBA9okWV8.mp4', '9lqoss_D_I-dC_Mv5-2XQjhkKq0.mp4', 'Fv5kt065SG5R_aRW4Q4Vy8cy4VI.mp4', 'fmRLf8uHBtofk4GsJQoQ4GiuGTs.mp4', 'L9YRVnUN0uFijBNE9GWx85vxVeA.mp4', 'KG3IqPwDOmE7obHXAAssKNo7OMU.mp4', 'Y2M_X3v7ZXbltIr4eQ71s5HLmuI.mp4', 'SzFxyf3hvozXHVaX1Z3g9_KQMfI.mp4', 'geP6sXaP3lPaE5TE8gBnBk1JtZw.mp4', '4xzVoSXx1gMkDNsTlA3ieJBr340.mp4', 'cnIFcrK93JSDcbDdUyY1j5Ol7-U.mp4', 'SlXyEM1Om-XUbOFZrSYiZ9cKn5s.mp4', 'gGo6ORdnHqjsa9bDh812vLXBOYo.mp4', 'q1KFsxon0GjjjjB8cjnrSGIWZPQ.mp4', '1BXZWiyX0X03CzyPayGpCu7YgtE.mp4', 'RfELtbhRwYwItcjbdg23qgyNlsY.mp4', '3Vncl-FFS5bJmWlv3qiCWYYLH7g.mp4', 'fUyXPmshpJau85wfQPiwPwAXIJw.mp4', 'vilmozXUFX_inlHr1lEz8DC9bko.mp4', '3-rwhnCTK2hbbto7Sj2vBfsZDx0.mp4', 'wWahe0A7Oat-xFTdrBE_3TTHWQE.mp4', 'BWWgD1dORbNU97pPDDOzmUI11G8.mp4', 'kq2m09JHMkUstQI12VRrp2e-WkA.mp4', 'yiJV3yH5y-hh_7PtyDR0zcY9zf4.mp4', '1HP9zk9KCU0qee5vGssXYgYpWrs.mp4', 'DmxxdY1GYXIwwG0vEQ8kNyu6agY.mp4', '21RXg717R-hs56V42PYWWJnnCOs.mp4', 'g9qCNMHWiu2AfPlmfd3hmJOumRk.mp4', 'yvX_6-vlvYfDSbo8vK0OZN9Tepc.mp4', 'SxPtk6z9Y4Y5y0Yy6Md0CHcje9Y.mp4', 'ertfVsMY5FjtwacxDPLODYwo8Kc.mp4', 'PhgXyd6ZBIqoG1VxmX5jsg0_iLc.mp4', '-anpVMpQYu3enZIcfOuQgWfA80E.mp4', '7MgrWJvXI5sfp6lIBADTPQP8tmg.mp4', 'tETe7edpjtQ3IC9VaRxup0JroR8.mp4', 'xk3Ii0A7irydqPS8LToylRIvpXE.mp4', '7UyCT9YkgKonKfHWrskWi5K_xwo.mp4', 'NmVoxk255QTTSeS0tyIhHiRUSnk.mp4', 'lNjrixW0A-0wRtJvpW5avmFUddo.mp4', 'WGci8ThPXGlPs7roF7qHt0yRhVQ.mp4', 'oy-8dWnZABaID0_3GmchrEZrpvY.mp4', 'yr0vklr8v7byzBG6DwsjylRIgyU.mp4', 'O2LSpaKrXG3b5eQ4ZOcewszslto.mp4', 'irz8BmTR75GkB5cAKlG1KBi5JIw.mp4', '4Dqbab6iqY65fauD8b9DeuYTHaI.mp4', 'tcTr_lybhVzzaesordWcTj3nZdI.mp4', 'XmnX3kNBcxlGms7LndtJwKouDgo.mp4', 'HgnfhbGj_W9G8dmByVVZO9z7130.mp4', 'ZEdBJxEYCCiv6g_3M5q_uMDSEZo.mp4', 'bbyWSePZkffL4aHZ_ME5IktWnPA.mp4', 'bWgLFUmyFq7ivjjgdIaR934k3gM.mp4', 'jiKy4qS4CElDbekascHxUj-YV70.mp4', 'DhM1wVqN1gn8yID9iCaurj7sP00.mp4', 'Kxz-tj-KtK1xIG__UWIiqVkvpXE.mp4', 'dhOxxdEDZ3GUlbTbvEe0HXgtNCk.mp4', '7AiqY2ntXt8OhaOacLlHxnYowvw.mp4', 'pzeGIDp74ntF4QVdr80d5oVS7Do.mp4', '2aE7M8HxGimXXPv_j9KWrvoqQrY.mp4', 'kXfStCP2Vr2lgEvLFBucPpj4zUQ.mp4', 'jVtai_VCJ7s0g8o_gO3ZiSUZJtI.mp4', 'kyAFusmXBUnYpWC8tc5Io_YGG7I.mp4', 'hDhOlAsMgf__DuHEKQ0OFUne344.mp4', 'X1t2VhZDxwoR33lsWGQLn6H2FkQ.mp4', 'h8nMpPUC-bIh1dNpgsRUMJdWwZ8.mp4', 'EM4qlf2zXuFOqZlT7xI0oTm7axw.mp4', 'fnBuwLHdVDQw2jWrypyHOL0idQs.mp4', 'UrJTPB05faHM2_jEB8TlISNlj_k.mp4', 'Bear2C-luP-5walclY-5-vCgxOQ.mp4', 'zPq_oGihC4AbO-HMwux7girMHcs.mp4', 'h2oYY97MHJflLZfOHrUgVzpryII.mp4', '5bokRGcHMavJ2cX1mijRqVZY1GQ.mp4', 'GS6fOJmxrWNn7qK-cUpnHkvM0XY.mp4', 'mEebysZI_Huv8wAw7zHqw5uNoZY.mp4', 'CB7W_p7pGIkBz9e1QEqmZkMCd3I.mp4', 'roOEyBMNDdjO7hhc0FdVtoP2q0g.mp4', '_JSOlGcOITaGnTSjjicz9HF5WvE.mp4', 'qqdOo3_vQsR1eOau-_mz6Ab9JcA.mp4', 'JgzcnbjpdEWPdNPBII2PZZvfSEE.mp4', 'eXjoDD5bE1SijQApalFb_TF60_Y.mp4', 'LzKWYWX0HDpEDdXuy06xPj_MdRI.mp4', 'nBTzxMh9yMS7Q514eBUOSx-_GtI.mp4', '0IAFbh5JOGYgzgzyEMeYlaSJFpw.mp4', 'zojVjkbQ71p7m81PAFgIUgABSVQ.mp4', 'voBEKsjhvnbr7-1Dii8p4G7qDwo.mp4', 'ARocInJFjkbkjwZgWZFyI64nqDQ.mp4', 'bCIr4BDIOyOdUjA2F7-wSgD9-Gk.mp4', 'fhGnatg4P0QmjVKcOcRGBsgKXKQ.mp4', 'xLRR-LQ1ny_dOejb8fuQFfAlCSA.mp4', 'TZozoAdxxxja3d_5a0n1kHulDO4.mp4', 'zij8mCgOdL32klEJ4LQ8T9iVtlI.mp4', 'otOFYptsU4ZZqETszN_4u294WnE.mp4', '5FopJdwlC3qmLQMVWNE0gN_5y-8.mp4', 'CjkNtoCT5H9ge4XdNoG5sOUjfq8.mp4', 'ztV6cynSGBFroKeEJ-szr7UglUk.mp4', 'iVt4FTySySYyGWyjnJdaukChxr8.mp4', '3GpJ-5T0zGEhlM69NE-YDOhuddU.mp4', 'nmBgtQiIVllCEhJOtZ-YCVk0gTQ.mp4', '7ytLv1uRWtxXTaZW1Z-tc1x1MOU.mp4', 'lU99WmzzXXRzHDO9wXQA_NKwHRA.mp4', 'Neg58Yp8N1f4huh2V5Xp8gKgwao.mp4', 'fEemFbB-CQaJ3ERq9Bvl-vNUC50.mp4', 'DIcwYuvVcQtQ7FUmWzpbpo9LK_E.mp4', 'aTzCUH8PqsExNVZCJB64hqW3DJA.mp4', 'U7b5HlVrtjOuVWFUe6FRtsJhqkg.mp4', 'g1uRd4pIOiMQmcDtOZ6-FSNWBUo.mp4', 'm1UCHlbMSBgGhkj9ndGAJk06GSM.mp4', 'ZzWHSeMyV8ONILA9HBun3oFHZcQ.mp4', 'ySuVi6Sd7KkbTVSCKBe07WZUDZY.mp4', '9EuKl7YZK4h922HmxEGA0z1BibU.mp4', '21Ents09XVihPm8phydICBmRuMs.mp4', 'fZ09ZAlhUdYHAu60Cufv1x2y20M.mp4', '1yvSUxW8hTjUVQVIvk1zq7U5G2c.mp4', 'hhq3BkomkHvWLHjdhVLwAuNq0YQ.mp4', '0wZDhow_l52wYA8alog4gdy6xgw.mp4', 'j5nGmAW0zsAMRXotf6r4CdB65C0.mp4', '81CEXb7GD_FGYtDvsAarelU2S6Q.mp4', 'sNJIBQDVLVDPmp1J28pmG5dmuD8.mp4', '4HWMFrkv7Nll1ZH03gZVdZ1GxFI.mp4', 'wOweAWEbNB7uwEwXUnZe2GZS6Ls.mp4', '_j9WgGKppvQjcIb54QSo89GB_3k.mp4', 'b4s8MdRJsaDRZ2V5DN84j3PmQW8.mp4', 'OlpEkIVlS-ZczI20nQ6RBI7D0Ws.mp4', '0oLuzfUSf0l5UPqeDI3nX2T7vQM.mp4', 'xYcmBsrk8SL3ubdouk15BqupRlw.mp4', 'z-QLoz_RmrkkjKVEmcazPeBYE_Q.mp4', 'h0ic_4_JTi6ALXtqQ8NWsrhsYPs.mp4', 'uBX34evW6Xc96d3dwAkiR-aYCj0.mp4', 'zXy7336ZlDJX8p48RcVbGx2cQ-o.mp4', '5uMBTc7P1-IxMLVXW57MX0SRJF0.mp4', 'BgI-O48focrlYunGBR9NOljeM-8.mp4', 'BqpGOsznEVLmjA5Nx-Y8T3mf7rE.mp4', 'rOHb06Mgzev5uUOEJ0LOqoLYxc8.mp4', 'Iio_VdPAdnpzwvYBpWMFH5U2QFA.mp4', 'Xu2o_BRA_Pqsrq2Rfb7H93GUQtc.mp4', 'xoNPIEyL5lRLTKcnfF5YOKc4TZc.mp4', '3mllksvgdjccoqgJ0VqgLM7k71A.mp4', 'Ox0n1-O-GBuD72HUnJnut-dSQJ0.mp4', 'cHbfYn35ZWLFT4Tv0RXJfGh3Fqg.mp4', '-N8pLAcQZkz_AFyX2hBBuOyx-ok.mp4', 'C8phPtVJtBGrOvIUlaUf2db20b4.mp4', 'xQr5Pb2-svnmlxfZ61KxjXI1F3Q.mp4', 'SJ4Rw0yEaMnDcm_qvQEq2xUkbv0.mp4', '_EKnW1ooE4_ilo1w4vAvCZxXmJE.mp4', 'ZrK7OcFM0zCvfVGua-NCfyY57o0.mp4', 'zyL_YzpJLyD5udgyoHJCWDyvZPI.mp4', '1YGJwe_YtfLx2EAFgmm6njWqH8E.mp4', 'Nu4KFKt7bxraSkahPJfMTCCUnwg.mp4', 'sNwY_Zp1pcNS-UAvhWBTcc0C20A.mp4', 'DOtuevlo4kHQmMNTvEzyVdFM5zQ.mp4', 'STaCCJylYdDTijqqxIEFOybeUSo.mp4', 'eeEi2Ypqg2Ls09pcB984n_pkAQs.mp4', 'yRALUuKXvI3Z90Z3zLCjYlCqx_4.mp4', 'qpD1inGFBP0tP5cYfzC8DF6ASe8.mp4', 'tG78Iq_aVHuU_uJWUvrQiwwDiRE.mp4', 'jZXqkHxLR1ib3lKHSXaau0LPzlg.mp4', 'KHYoMWmix7n4w35ETxhSjZzq7Mg.mp4', 'RH80lSlqgFT6BKb9y-bU5AQ9IdI.mp4', '8GQvn9JSU5JBrY8Zw_IoVbI092o.mp4', 'XzOuZDw7DEuvW1vZvd1DslXXqg4.mp4', '8-DdOmO_PogqI0TzR6ezNWrET5o.mp4', 'yHLPQMlCJoL7vkS4CPffxdXvoMo.mp4', '6yjmMPQ9z7l70uahiGmqfkpC45Y.mp4', 'VHnRPM2DLv-FmAjex1t-PB3Cc8w.mp4', 'swHB6mHAkorumMjHvXfSXExCUhM.mp4', 'WkV0eli4KKi4GEk97LGDkCErL-w.mp4', '2313rY7C3FDrdvgFuKYJY2-EtB4.mp4', 'niztOTAVU3kz9Wto8M3A-uME04A.mp4', 'p_D-fWGyrj3OkzB91HuBLOyVEGo.mp4', 'mMmcc2wxueqi-FWTr38KQa6mmpA.mp4', 'dwaFz2_Z2KFZXnHJvmCLMI82DRA.mp4', 'tssLYUCbDVRCDMI9jzYDa1AUEQs.mp4', 'X7qE555Y60JXwJe11_ehHWs8VcI.mp4', 'uA76JLHPD8tjURjySbrufGB5f3o.mp4', 'fylAr6YZD2wIPMoK91Gql-iz3RM.mp4', 'THO_7cyjq53kwzWelifuXoizulk.mp4', 'Rifk6LcrH1M3N23pMCznKtut3Hk.mp4', 'SrSr6jUyUOiOd6J5zxLEZHek-Qk.mp4', 'eAENNENtYv_dw4rwJSlSVm2CDbc.mp4', 'XPlonplSngWFLEPXWvXpntNv6IU.mp4', 'G1rdBX8LWeMrAKc05apOiT7-Apc.mp4', 'l4HAcefHlXPFpGiWmPOgT1sCIbM.mp4', 'HNqsAykfMP57Wwu4P-nkWBFSISU.mp4', 'ig2KVDbTYyIdgEgoII1sgzQF9mQ.mp4', 'VWO8Nu_ABpoP65nTUJ68CCugPgs.mp4', 'F3dz0Dfm3Se6NN9QbL9h-HaHZSY.mp4', 'zBRi3wsAJ6Cpm5CUZjCqxXbWZ4Y.mp4', 'ZPkXUlm6zqSog_xdG_O7AOF7jwc.mp4', 'PL38Z6rpmg9iyHEto0wfQ7Vpi2o.mp4', 'uUIKWQ9REZjhJgPagpiAbpUfqkI.mp4', '7vGGpytd20U6KoREnnUz40GlRXw.mp4', 'pirXRIYQcugr1r2Z_or7KYc9QRA.mp4', 'wOZolj2IFyBnG8dbw5XqNuPyHLM.mp4', 'KeXNB-iOKPrHw72OYoeFJ4rKxGo.mp4', '1WakKhz5AUPF4OmtN_RtP7lQlQQ.mp4', '1iKuG4xt7RcJqwiHN-oHhNiu_Kk.mp4', '9GpxW4hIPofRY2-oHTL9fc4NCHM.mp4', '3nlDXWQxQy0sreULOnMBDrRdxAs.mp4', 'Fg86cTmQeKl3sz7CsNnFih1JMBk.mp4', '2OrV7lvQgKElEsSHHoXxPVU6LsQ.mp4', 'eHf7IThjyinA4tfCGfyFnehkBNg.mp4', '6xTqLCmgrzOHLClws6WvvSOaqOw.mp4', 'IL3CxpfXJjgq9CuVncfIK6WUqZ0.mp4', 'vwklHHF29MSTV6aeOaoUaqRELTU.mp4', 'I113Q8zevH52Mga1fMXppAIOEFo.mp4', 'YOEhxHEej0GyHKR40TwX4T4qtws.mp4', '5gLRfizpxTdUdvqKbSEzx61DKgE.mp4', '4M3oBDjMfGLFD7cuLLtb6k1bo7M.mp4', 'ld8dx3olAfZeDMaeEhSP4XQVeXk.mp4', 'xAyoap17gaORoFMIXp7fEV_7U2s.mp4', 'NCQtI8_0mteCpjdOjmTHwUAVMLM.mp4', 'pvNecbUUHodHeuzWO5sz8JkqhlY.mp4', 'Ej-TFdNUG7TXGDzZ9uxAjWHGu6g.mp4', 'msnZkIwQJqBdszocsHVezR5o3LQ.mp4', 'zpXAMHONaofP2WkdYAZTPV1lU1s.mp4', '6LlWPoTOOP2Qj66qUiwfsmCIsDo.mp4', 'D1TI2XPE-y3985DRodqA-M4FV0o.mp4', 'CvluU-jhjnBhfU6lXP6I2v_pbQI.mp4', 'BehoQrICYcQjBcpcRrvIFargrhs.mp4', 'Psq9TAdfU7cG4Htlw0vntmIy5ss.mp4', 'OzCxcbHEZof9z78nfWhvPnD43WU.mp4', 'R_Hn-6Yp4sSXs4dH_Gyth-jvMi4.mp4', 'QhEbz9whfVBvqlvZwezO3zlgOWU.mp4', 'd3z7yACbLW7-6WuOylItuBEoRJE.mp4', 'tAcAqwyfrB-eRawj4JzeXpPmOgk.mp4', 'bcQ0nUsD6BIMOCwCPULpkDzjInU.mp4', 'IvxD8cgFymH_0ZXpa-7bVDzc9KM.mp4', 'M418bkv_Uur1kYSKjaBsKmeNe9A.mp4', 'GIKyw797YvgoZKddQCgsgwHp3GM.mp4', 'nzAQYrJgUMUsu_IqW-jaX4TCr8A.mp4', 'mUFAX5j79Qf45-TicCBKhjHuXxQ.mp4', 'Pjy0-H1QEEAftJ6jKjyd-zSEggM.mp4', 'NXHYrShYcDEXQbb2KXnaTx6klFQ.mp4', 'GuViBXesuzrHuSc_n_IJEPs4dnA.mp4', 'b-Fe1BYTgffihkSHawVbSnDFhag.mp4', 'rEiYRIrGgHnnk_5gYrlIzfSDz_k.mp4', 'YfX9oF_Fka8ITOhlO0Kh8rz9T60.mp4', 'sK_Uyz_sEqu0TEW4wOrs_0hFd88.mp4', 'EOh_S04P_MRnAAgWw0roUUUFYVQ.mp4', 'r36ufecQEr_2Uav9ZXz9Gu0QV3g.mp4', 'NdH1SISX8_uQg955YwGpTYTFTeg.mp4', 'CD8PpqearTphSt-ZsqEBITlO1sI.mp4', 'kTYTTzDaNnbqy_EoqyMU9KhfVtw.mp4', 'LftA7GhEK962RmQXZ6KZ3ZMpDbs.mp4', 'azVLFO5yMaDGHAgkZB8bhYZslYk.mp4', 'PKh2LPPY4FpWpMr8gYTTc-OzBU0.mp4', 'mA-0niJnJIcRjDAauZ_iGLfIt8c.mp4', '_nIyqIZnrts7BNFT961kkj36UXU.mp4', 'oesaw0deyLmtIflYANhgy8RL0qY.mp4', 'WBg4N1n8tVqp0DydBamUjiGnS-Y.mp4', 'X3qnhN8UPXVp8OXP9wo5Cuvlkns.mp4', 'KewDIqJQ-jubya1H-mOUBn1SMAg.mp4', '-UKZwLPOm_0d2-cpE9A31G7s75s.mp4', 'JXKMuwxTdJtnprXysiSjDiLlywE.mp4', 'tLMsM8t7PmPy4x8DtmnT9zkBe7A.mp4', 'dYZBUujT4WOZyyPEAk08yu5uDeI.mp4', 'beGX6sXHKTvGEqNPfmqicklZnDo.mp4', 'CZTRRGrg66ycsGoPfUJh6rAoM8c.mp4', 'kkLDCRfUhBTJja6Fwuux3d148BA.mp4', 'xMVfjm8pxPMiUKVH_ACs3-4BlsM.mp4', 'acTO-LffUxr20DAh8Y16z4zns0U.mp4', '3yh4ejPv8AnX01qyQ7p4ItqqidI.mp4', '10S4w-2Nicy4gWcIzewGooLx_ks.mp4', 'AHBRGSDZKgMgSSKKVCdTMeg6SPw.mp4', '-iFzAnJoibc2plYhhADtGOeHS68.mp4', 'Hqx8aym--_P3sXAlx-2cSknL6Ng.mp4', 'XvbrJ-qLl_TWoNoySQrAdEQ8m6Y.mp4', 'kGFu8qJkzxoApp2E_xJ7T_DpcpE.mp4', 'vdvAGDrMbcxBlSO6KGUetKwJDPI.mp4', 'cgPbfx61LUCqoLXRWhCI_Wgtxd0.mp4', '8u9HTeqRiDx6YG7mttoXuscuyr8.mp4', 'i1fbfIDGbnVm7i_0DQF61ZBvGII.mp4', 'f62h_i6rYDmP8yotoMPx65jwMUQ.mp4', 'c14ZWnXCetay1CCu869mPCwhnIs.mp4', 'gdHe1eP-wFDKEiZedcOKZTyOq1s.mp4', 'YvaXaELDflZXvU8y6I2KSDtOM4g.mp4', 'UMEtLxt7h9kFDDCh5SDb56sQeBM.mp4', 'A175_IqifUPpJAvU2WFKF5qZzRc.mp4', 'eCgNUXVTOzkKSnlJLH6Hb_xIWqo.mp4', 'SLSCN_YV1qROZmFRuUxkNs3nRKo.mp4', 'IhahnTnKi_8I30fonYD2KRC0oeY.mp4', 'HAxnvbWGWsQbITmKtT5IZHk2weQ.mp4', 'SXm239s91sDxBhfi_JUT5Nm8X4s.mp4', 'vegd3upTOmgopaO_3Tgac9gHCZ0.mp4', 'lEwFU-mC0qOKXatMQ4muXyZqJcs.mp4', 'z2AuUugw5aEW63Icgj0L6aM_BjA.mp4', 'p-IWMRVnj7ov0PayjOUDTNNbSgE.mp4', 'FLPd_0LNUc-wKVgv946dZQ9NBfo.mp4', 'TVZL8inNFptcvaTuFjLFl_NZb9M.mp4', 'o3MtIQ4B4yRVQIv-OMSGxLEq0yg.mp4']}\n",
      "Len of real_real: 37\n",
      "Len of fake_fake: 387\n"
     ]
    }
   ],
   "source": [
    "clean_vids = check_all_names_found(\"video-data/\", \"video-metadata-publish.csv\")\n",
    "bof = clear_unknowns(clean_vids, \"video-metadata-publish.csv\")\n",
    "print(bof)\n",
    "print(f\"Len of real_real: {len(bof[\"Real\"])}\")\n",
    "print(f\"Len of fake_fake: {len(bof[\"Fake\"])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b5dd4",
   "metadata": {},
   "source": [
    "Make a manifest csv to share what videos we will use for the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f824e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 424/424 [00:05<00:00, 81.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: 90.70 s\n",
      "MEDIAN: 43.37 s\n",
      "Q1: 21.64 s\n",
      "Q3: 75.23 s\n",
      "Q.95: 250.03 s\n",
      "MAX vid length : 5632.87 s\n",
      "Pruned videos that are outliers/too long\n",
      "(318/424 remain)\n",
      "Filtered manifest ➜ manifest_pruned_outliers.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir   = Path(\"video-data/\")\n",
    "real_files = bof[\"Real\"]               \n",
    "fake_files = bof[\"Fake\"]\n",
    "\n",
    "def make_manifest(names: List, label: int):\n",
    "    full_paths: List = []\n",
    "    for file in names:\n",
    "        full_path = base_dir / file  \n",
    "        full_paths.append(full_path.as_posix())\n",
    "    df = pd.DataFrame({\n",
    "        \"path\":  full_paths,\n",
    "        \"label\": label\n",
    "    })\n",
    "    return df\n",
    "\n",
    "manifest = pd.concat([make_manifest(real_files, 0), make_manifest(fake_files, 1)], ignore_index=True)\n",
    "\n",
    "def video_duration_tc(path):\n",
    "    \"\"\"\n",
    "    Returns clip duration by seconds (roughly).\n",
    "    \"\"\"\n",
    "    vd  = VideoDecoder(path)\n",
    "    meta = vd.metadata \n",
    "    # print(meta)\n",
    "\n",
    "    if (not (meta.average_fps is None)) and meta.average_fps > 0:\n",
    "        return len(vd) / meta.average_fps\n",
    "\n",
    "    # 2) header already stores duration? (not always present)\n",
    "    if meta.duration is not None:\n",
    "        return meta.duration\n",
    "\n",
    "    # 3) as a last resort, decode one packet to query its PTS\n",
    "    raise RuntimeError(\"no duration information in header\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  Enrich manifest with duration & drop unreadable clips\n",
    "# ---------------------------------------------------------------------\n",
    "durations, bad_indices = [], []\n",
    "\n",
    "# any time you see tqdm its just to make the progress bar, dont worry about it\n",
    "for idx, row in tqdm.tqdm(manifest.iterrows(), total=len(manifest)):\n",
    "    try:\n",
    "        durations.append(video_duration_tc(row[\"path\"]))\n",
    "    except Exception as e:\n",
    "        durations.append(np.nan)\n",
    "        bad_indices.append(idx)\n",
    "        print(f\"BAD VIDEO {row['path']} unreadable erorr is: {e}\")\n",
    "    # print(\"adding\")\n",
    "manifest[\"duration_s\"] = durations\n",
    "\n",
    "if bad_indices:\n",
    "    manifest.drop(index=bad_indices, inplace=True)\n",
    "    print(f\"dropped {len(bad_indices)} because they couldnt be opend\")\n",
    "\n",
    "manifest.to_csv(\"manifest.csv\", index=False)\n",
    "\n",
    "#-------Some videos are way too long, need to remove outliers-----------------------------------------------------\n",
    "df = pd.read_csv(\"manifest.csv\")   # or \"manifest.csv\"\n",
    "\n",
    "dur = df[\"duration_s\"].to_numpy()\n",
    "\n",
    "print(f\"MEAN: {dur.mean():.2f} s\")\n",
    "print(f\"MEDIAN: {np.median(dur):.2f} s\")\n",
    "print(f\"Q1: {np.quantile(dur, .25):.2f} s\")\n",
    "print(f\"Q3: {np.quantile(dur, .75):.2f} s\")\n",
    "Q50 = np.quantile(dur, .50) # median lol \n",
    "Q75 = np.quantile(dur, .75)\n",
    "Q95 = np.quantile(dur, .95)\n",
    "Q25 = np.quantile(dur, .25)\n",
    "print(f\"Q.95: {Q95:.2f} s\")\n",
    "print(f\"MAX vid length : {dur.max():.2f} s\")\n",
    "\n",
    "\n",
    "before = len(df)\n",
    "# df = df[df[\"duration_s\"] <= Q95].reset_index(drop=True) If I wanted to \n",
    "df = df[df[\"duration_s\"] <= Q75].reset_index(drop=True) # drop the ones that have about Q threshold (pruning super long vids)\n",
    "after  = len(df)\n",
    "\n",
    "df.to_csv(\"manifest_pruned_outliers.csv\", index=False)\n",
    "print(\"Pruned videos that are outliers/too long\")\n",
    "print(f\"({after}/{before} remain)\")\n",
    "print(\"Filtered manifest ➜ manifest_pruned_outliers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adac529e",
   "metadata": {},
   "source": [
    "Make the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808eb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/avdf/lib/python3.12/site-packages/transformers/configuration_utils.py:309: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# read rgb vals for a video and store them in a tensor\n",
    "_img_tx = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ConvertImageDtype(torch.float32),  # → [0,1]\n",
    "    T.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]) # → recenetering [-1, 1]\n",
    "])\n",
    "\n",
    "def read_frames(path, fps: int = 2):\n",
    "    \"\"\"\n",
    "    Decode `path` with torchcodec.VideoDecoder and return a tensor of\n",
    "    shape (T, 3, 224, 224) normalised to [-1,1].\n",
    "    \"\"\"\n",
    "    vr = VideoDecoder(path, dimension_order=\"NHWC\") # each is (H,W,C)\n",
    "\n",
    "    src_fps = (\n",
    "        vr.metadata.average_fps\n",
    "        or vr.metadata.average_fps_from_header\n",
    "        or 30.0   # fall back in case nothing else is true\n",
    "    )\n",
    "    step = max(int(round(src_fps / fps)), 1) ## make the parameter fps super low if you want to increase video speed, lose data from this though\n",
    "\n",
    "    frames = []\n",
    "    for f in vr[::step]: # move through video in our step size\n",
    "        if isinstance(f, np.ndarray):\n",
    "            f = torch.from_numpy(f) #converts numpys to tensor\n",
    "        frames.append(_img_tx(f.permute(2, 0, 1))) # reorder  to C,H,W\n",
    "    return torch.stack(frames)       \n",
    "\n",
    "\n",
    "#Audio section---------------------------\n",
    "\n",
    "# helper to use torchaudio if it works for the vid, if not use ffmpeg\n",
    "def _load_audio_any(path, sr: int = 16_000, mono: bool = True):\n",
    "    try:\n",
    "        wav, sr0 = torchaudio.load(path)          # tries 'soundfile' backend\n",
    "        if sr0 != sr:\n",
    "            wav = torchaudio.functional.resample(wav, sr0, sr)\n",
    "        if mono and wav.shape[0] > 1:\n",
    "            wav = wav.mean(0, keepdim=True)\n",
    "        return wav, sr\n",
    "    except Exception:\n",
    "        # ffmpeg fallback \n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", str(path),\n",
    "            \"-f\", \"f32le\", \"-ac\", \"1\" if mono else \"2\",\n",
    "            \"-ar\", str(sr), \"-\"\n",
    "        ]\n",
    "        pcm = subprocess.check_output(cmd, stderr=subprocess.DEVNULL)\n",
    "        wav = torch.frombuffer(pcm, dtype=torch.float32)\n",
    "        wav = wav.view(-1) if mono else wav.view(-1, 2).t()\n",
    "        return wav.unsqueeze(0), sr                # (1,N), sr\n",
    "\n",
    "# 3.2 wav2vec2 model & processor (loaded once)\n",
    "wav2vec = AutoModel.from_pretrained(\"facebook/wav2vec2-base\").eval() # pre-trained voice recognition model. Seems to be a standard\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def read_audio_embed(path, target_T, sr: int = 16_000) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return a (T,768) feature sequence aligned to the number of video frames.\n",
    "    If audio decoding fails, a zero-tensor of the right shape is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wav, _ = _load_audio_any(path, sr=sr, mono=True)   # (1,N)\n",
    "        feats  = wav2vec(**processor(wav.squeeze(), sampling_rate=sr, return_tensors=\"pt\")).last_hidden_state.squeeze(0)            # (N',768)\n",
    "    except Exception as e:\n",
    "        print(\"audio failed, putting 0's in its place\") # This shoudlnt happen anymore now that I filtered them out\n",
    "        feats = torch.zeros(target_T, 768)\n",
    "        return feats\n",
    "\n",
    "    # temporal alignment to video: linear index sampling\n",
    "    idx = torch.linspace(0, feats.size(0)-1, target_T).round().long()\n",
    "    return feats[idx]  # (T,768)\n",
    "\n",
    "\n",
    "# 50% cross modal masks like the report says we'll do\n",
    "def make_masks(T, p = .5):\n",
    "    idx = torch.randperm(T)\n",
    "    n = int(T * p)\n",
    "    vmask = torch.zeros(T, dtype=torch.bool)\n",
    "    amask = torch.zeros(T, dtype=torch.bool)\n",
    "    vmask[idx[: n//2]] = True\n",
    "    amask[idx[n//2: n]] = True\n",
    "    return vmask, amask #(torch.Tensor, torch.Tensor)\n",
    "\n",
    "\n",
    "#Dataset wrapper\n",
    "class AVDeepfakeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv, fps: int = 2): #default fps if none is passed in\n",
    "        self.df  = pd.read_csv(csv)\n",
    "        self.fps = fps\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        path  = self.df.at[idx, \"path\"]\n",
    "        label = self.df.at[idx, \"label\"]\n",
    "        frames = read_frames(path, fps=self.fps)\n",
    "        audio  = read_audio_embed(path, frames.size(0))\n",
    "        vmask, amask = make_masks(frames.size(0))\n",
    "        return frames, audio, vmask, amask, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f4c69",
   "metadata": {},
   "source": [
    "I ran smth to find these and print them but it took 30+ mins to run on like 200 vids so I'm leaving it out of this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b80ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "318\n",
      "Rows left : 310\n"
     ]
    }
   ],
   "source": [
    "audios_dont_load = [\"video-data/fZ09ZAlhUdYHAu60Cufv1x2y20M.mp4\", \"video-data/sNJIBQDVLVDPmp1J28pmG5dmuD8.mp4\",\"video-data/F3dz0Dfm3Se6NN9QbL9h-HaHZSY.mp4\",\n",
    "\"video-data/uUIKWQ9REZjhJgPagpiAbpUfqkI.mp4\",\"video-data/YfX9oF_Fka8ITOhlO0Kh8rz9T60.mp4\",\"video-data/oesaw0deyLmtIflYANhgy8RL0qY.mp4\",\n",
    "\"video-data/KewDIqJQ-jubya1H-mOUBn1SMAg.mp4\", \"video-data/JXKMuwxTdJtnprXysiSjDiLlywE.mp4\"]\n",
    "\n",
    "# prunedf = pd.read_csv(\"manifest_pruned_outliers.csv\")\n",
    "# # print(prunedf)\n",
    "# print(prunedf[\"path\"])\n",
    "\n",
    "prunedf = pd.read_csv(\"manifest_pruned_outliers.csv\")\n",
    "print(len(audios_dont_load))\n",
    "print(len(prunedf))\n",
    "\n",
    "# keep every row **whose path is NOT in** audios_dont_load\n",
    "prunedf = prunedf[~prunedf[\"path\"].isin(audios_dont_load)]\n",
    "\n",
    "print(\"Rows left :\", len(prunedf))\n",
    "prunedf.to_csv(\"final_filtered_manifest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb21b8",
   "metadata": {},
   "source": [
    "Encoding video features with resnet50 pretrained and store them so you all are able to read the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860567bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "export: 100%|██████████| 78/78 [04:54<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch, tqdm\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using\", device)\n",
    "\n",
    "cnn = resnet50(weights=ResNet50_Weights.DEFAULT).to(device).eval()\n",
    "feat_extractor = torch.nn.Sequential(*(list(cnn.children())[:-1]))\n",
    "\n",
    "def rgb2feat(frames):\n",
    "    with torch.inference_mode():\n",
    "        f = feat_extractor(frames.to(device))\n",
    "        return f.squeeze(-1).squeeze(-1).cpu()\n",
    "\n",
    "\n",
    "ds = AVDeepfakeDataset(\"stored_features.csv\", fps=2) #higher fps means more data, you can edit this\n",
    "out = Path(\"feature_cache\")\n",
    "out.mkdir(exist_ok=True)\n",
    "\n",
    "for i in tqdm.tqdm(range(len(ds)), desc=\"export\"):\n",
    "    frames, audio, vmask, amask, y = ds[i]\n",
    "\n",
    "    key = Path(ds.df.at[i, \"path\"]).stem\n",
    "    v_feat = rgb2feat(frames)  # (T,2048)\n",
    "    a_feat = audio  # already (T,768)\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"vision\": v_feat.half(),      # float16 to halve the size\n",
    "            \"audio\" : a_feat.half(),\n",
    "            \"vmask\" : vmask,\n",
    "            \"amask\" : amask,\n",
    "            \"label\" : y\n",
    "        }, out / f\"{key}.pt\" # stored in feature_cache folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232bb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vision : torch.Size([4, 27, 2048])\n",
      "audio  : torch.Size([4, 27, 768])\n",
      "video_mask  : torch.Size([4, 27])\n",
      "audio_mask : torch.Size([4, 27])\n",
      "labels : tensor([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, feat_dir):\n",
    "        self.paths = sorted(Path(feat_dir).glob(\"*.pt\"))\n",
    "    def __len__(self): \n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, idx):\n",
    "        pkg = torch.load(self.paths[idx], map_location=\"cpu\", weights_only=False)\n",
    "        \n",
    "        return pkg[\"vision\"], pkg[\"audio\"], pkg[\"vmask\"], pkg[\"amask\"], int(pkg[\"label\"])\n",
    "\n",
    "loader = torch.utils.data.DataLoader(FeatureDataset(\"feature_cache\"),\n",
    "                            batch_size=32, shuffle=True)\n",
    "\n",
    "def collate_pad(batch):\n",
    "    v_list, a_list, vm_list, am_list, y_list = zip(*batch)\n",
    "\n",
    "    # --- pad features -------------------------------------------------\n",
    "    v_pad = pad_sequence(v_list, batch_first=True)\n",
    "    a_pad = pad_sequence(a_list, batch_first=True)\n",
    "\n",
    "    # --- create padding mask (True where we inserted padding) ---------\n",
    "    lengths = torch.tensor([x.size(0) for x in v_list])\n",
    "    T_max   = v_pad.size(1)\n",
    "    pad_msk = torch.arange(T_max)[None, :] >= lengths[:, None]   # (B,T_max)\n",
    "\n",
    "    # pad+OR with existing modality masks\n",
    "    vm_pad = pad_sequence(vm_list, batch_first=True) | pad_msk\n",
    "    am_pad = pad_sequence(am_list, batch_first=True) | pad_msk\n",
    "\n",
    "    labels = torch.tensor(y_list)\n",
    "\n",
    "    return v_pad, a_pad, vm_pad, am_pad, labels\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Loader that can be used wiht the model (given that you have the \"feature_cache\" folder downlaoded and in the project)\n",
    "ds = FeatureDataset(\"feature_cache\")\n",
    "loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size   = 4,\n",
    "    shuffle      = True,\n",
    "    num_workers  = 0,\n",
    "    collate_fn   = collate_pad,\n",
    "    pin_memory   = False  # no CUDA \n",
    ")\n",
    "\n",
    "#load a batch's dims for testing \n",
    "v_b, a_b, vm_b, am_b, y_b = next(iter(loader))\n",
    "print(\"vision :\", v_b.shape)   # (B, T_max, 2048)\n",
    "print(\"audio  :\", a_b.shape)   # (B, T_max, 768)\n",
    "print(\"video_mask  :\", vm_b.shape)\n",
    "print(\"audio_mask :\", am_b.shape)\n",
    "print(\"labels :\", y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6cbcec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "verifying: 100%|██████████| 3/3 [00:00<00:00, 41.40it/s, batch=3, samples=80]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅  finished without errors:\n",
      "    • batches  : 3\n",
      "    • samples  : 80\n",
      "    • frames   : 1,435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch, tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# -- 0.  dataset & collate ----------------------------------------------------\n",
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, feat_dir):\n",
    "        self.paths = sorted(Path(feat_dir).glob(\"*.pt\"))\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, idx):\n",
    "        pkg = torch.load(self.paths[idx], map_location=\"cpu\", weights_only=False)\n",
    "        return (pkg[\"vision\"], pkg[\"audio\"],\n",
    "                pkg[\"vmask\"], pkg[\"amask\"], int(pkg[\"label\"]))\n",
    "\n",
    "def collate_pad(batch):\n",
    "    v_list, a_list, vm_list, am_list, y_list = zip(*batch)\n",
    "\n",
    "    v_pad = pad_sequence(v_list, batch_first=True)      # (B, T_max, 2048)\n",
    "    a_pad = pad_sequence(a_list, batch_first=True)      # (B, T_max, 768)\n",
    "\n",
    "    lens      = torch.tensor([x.size(0) for x in v_list])\n",
    "    T_max     = v_pad.size(1)\n",
    "    pad_mask  = torch.arange(T_max)[None] >= lens[:, None]   # True where padded\n",
    "\n",
    "    vm_pad = pad_sequence(vm_list, batch_first=True) | pad_mask\n",
    "    am_pad = pad_sequence(am_list, batch_first=True) | pad_mask\n",
    "    labels = torch.tensor(y_list)\n",
    "\n",
    "    return v_pad, a_pad, vm_pad, am_pad, labels\n",
    "\n",
    "# -- 1.  loader ---------------------------------------------------------------\n",
    "feat_root = \"feature_cache\"\n",
    "loader = DataLoader(FeatureDataset(feat_root),\n",
    "                    batch_size   = 32,\n",
    "                    shuffle      = False,   # deterministic pass\n",
    "                    num_workers  = 0,\n",
    "                    pin_memory   = False,\n",
    "                    collate_fn   = collate_pad)\n",
    "\n",
    "# -- 2.  scan everything ------------------------------------------------------\n",
    "n_batches = 0\n",
    "n_samples = 0\n",
    "n_frames  = 0    # total (unpadded) time-steps for info only\n",
    "\n",
    "with tqdm.tqdm(loader, desc=\"verifying\") as bar:\n",
    "    for v, a, vm, am, y in bar:\n",
    "        # ---- quick consistency checks every batch --------------------------\n",
    "        B, T, _ = v.shape\n",
    "        assert a.shape == (B, T, 768)\n",
    "        assert vm.shape == am.shape == (B, T)\n",
    "        # assert (vm & am).sum() == 0, \"positions cannot be masked twice\"\n",
    "        assert torch.isfinite(v).all() and torch.isfinite(a).all()\n",
    "\n",
    "        # statistics\n",
    "        n_batches += 1\n",
    "        n_samples += B\n",
    "        n_frames  += (vm == False).sum().item()   # “kept” frames (≈ real length)\n",
    "\n",
    "        bar.set_postfix(batch=n_batches, samples=n_samples)\n",
    "\n",
    "print(f\"\\n✅  finished without errors:\"\n",
    "    f\"\\n    • batches  : {n_batches}\"\n",
    "    f\"\\n    • samples  : {n_samples}\"\n",
    "    f\"\\n    • frames   : {n_frames:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
